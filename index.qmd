---
title: "Exploring the effects of Receptive Fields in CNN"
subtitle: "Optimizing CNNs through effective receptive fields"
author: "Susanta Deka, Kalyani Kotti (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references_deka.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

[Literature Review Log](review.html){target="_blank"}

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd` to edit)


## Introduction

The receptive field of a Convolution Neural Network (CNN) is the specific region in input data that activates the neurons i.e. the features captured by a convolution layer. This region determines the level of feature extraction, or learning from the input which ultimately impacts the quality of the output. Different sizes of receptive fields may be optimal for different tasks. This also means that the effective receptive field for a given task will vary with variation in the input. For example a magnified image vs a large zoomed out scene will yield vastly different features for the same receptive field. In this study, we aim to identify the optimal sizes and combination of convolution filters for effective receptive fields for certain tasks. In other words, we want to experiment different configurations of convolutional filters and network architectures that affect the effective receptive field using different kernel sizes, strides, and depths across different datasets and tasks. With that we hope to identify generalizable principles for designing CNNs with optimal feature extraction capabilities.


## Literature Review

The history of Convolution Neural Networks (CNN) is a rich one and one that spans multiple decades. CNNs have made much of the buzz as well as many advancements in deep learning in recent years, particularly in the domain of computer vision and image analysis. CNN architecture is heavily inspired by the biology of the visual cortex, which contains arrangements of simple and complex cells that activate based on specific subregions of the visual field, known as receptive fields [@indoliaConceptualUnderstandingConvolutional2018]. Moreover, researchers Gu et al. point out about the rapid growth of annotated data and the significant improvements in the processing power of graphics processor units (GPUs) which has empowered research on convolutional neural networks even further leading to many state-of-the-art results on various tasks. [@guRecentAdvancesConvolutional2018]

There are numerous models and architectures of CNN. A review article by Cong and Zhou goes into details about the 6 typical architectures of CNN. CNNs typically have these five basic layers, the input layer, the convolution layer, the pooling layer, the FC layer and the output layer. The paper talks about how AlexNet used ReLu activation function instead of tanh to reduce computation complexity and resolve the vanishing gradient problem. Moreover, the use of Local Response Normalization (LRN) and pooling (down-sampling) were also helpful in improving performance as well as reducing overfitting. There’s also mention of ZfNet or DeconvNet where researchers provided visualizations to understand the internal mechanism of a CNN architecture.

The article then talks about VGG Net where CNNs are split into smaller filters (or kernels) thereby increasing the depth of the network. There’s also mention of GoogLeNet and its use of multiple filters of varying sizes stacked together to extract features of different sizes. The authors mention that Batch Normalization was a major contribution with the introduction of InceptionV2 model which improved backpropagation and the gradient vanishing problem.

Then there’s the idea of cross-layer connection which is different from prior architectures where connections existed only between adjacent layers. ResNet implemented this cross-layer connection through shortcut connections where the input is transferred across multiple layers and then features are aggregated which improved accuracy. This is an example of widening the network which is opposite to that of deepening the network. Finally, there’s info about the DenseNet which is a CNN architecture with dense connections where each layer is connected to every other layer. A bad side effect of this is that the model relearns the same features repeatedly.

The article then looks into lightweight networks which are targeted towards mobile devices or embedded devices. Lightweight CNNs are smaller CNN architectures obtained after compression and acceleration. MobileNetV3 is a lightweight CNN that decompose the convolution process into pointwise and depthwise convolution for decreasing model size as well as compute burden.

The fifth type of CNN architecture deals with object detection. The article introduces Regional CNN (R-CNN) which achieve object detection through three main ideas which are region proposals, feature extraction and region classification. Inspired by this and based on GoogLeNet, there’s a new detection method called the YOLO model, You Only Look Once which segments an input image into multiple bounding boxes and classifies the regions alongside the bounding boxes to detect objects.

Finally, the last architecture is the Transformer Encoder where the article looks into Vision Transformers (ViT). Because transformers by themselves lack spatial inductive biases which leads to poor optimization, researchers have combined CNNs and ViTs to overcome it. [@congReviewConvolutionalNeural2023]


## Dataset

For this project we have decided to use a dataset based on the Carla Driving Simulator, an open-source simulator designed for autonomous driving research. Carla provides a realistic and diverse set of driving scenarios that are ideal for training models for tasks like lane detection, object detection, and semantic segmentation.

* Dataset Source: Carla Driving Simulator.
* Type of Task: Semantic Segmentation for lane boundary detection.
* Image Size: The images in the dataset have a high resolution of 1024x512 pixels, allowing the model to capture intricate details of lane markings.
* Annotation Format: Each image has a corresponding binary mask, where lane boundaries are marked with 1 (lane pixels) and the background is marked with 0 (non-lane pixels).
* Driving Scenarios: The dataset contains various scenes, including urban roads, suburban areas, and highways, with different weather conditions (sunny, rainy) and times of the day (morning, evening, night). This diversity in conditions helps simulate real-world driving challenges.
* Image Channels: The images are in RGB format, meaning they have 3 channels (Red, Green, Blue), and the corresponding masks are single-channel grayscale images.

This dataset serves as the foundation for training a Convolutional Neural Network (CNN) for lane detection. The CNN will be evaluated on its ability to identify lane boundaries in diverse driving conditions.

## Dataset Visualization

The dataset contains over 6000 images of road scenes and label images for training and validation. 

Example of one of the images.

![](https://imgur.com/sAVhGgC)

The label image is a grayscale png with 3 pixel values, which are 0,1,2.

![](https://imgur.com/2A3k7z3)

The following image is the label image visualized for human eyes with visually distinct color values. Here we can see the lane lines which serve as the label for training.

![](https://imgur.com/LAKKKlk)

### Receptive Fields in CNNs

In Convolutional Neural Networks (CNNs), the receptive field refers to the area of the input image that influences the calculation of a particular neuron in the output feature map. Receptive field size plays a crucial role in CNNs, particularly in tasks like semantic segmentation, where understanding larger contextual information (e.g., the full view of a lane or road) is important for accurate segmentation.

* Smaller Receptive Fields (using smaller kernels like 3x3) capture finer details and help the model focus on localized features such as the lane markings.
* Larger Receptive Fields (using larger kernels like 5x5 or increasing network depth) help the model capture broader contextual information, which can be essential for detecting lanes over long distances or in complex, curved road structures.

In this project, we experiment with different receptive field sizes by altering kernel sizes, stride values, and network depths to analyze how they affect the model's ability to detect lane boundaries accurately.
Optimizing Receptive Fields for Semantic Segmentation in Lane Detection
To optimize receptive fields for lane detection, we can adjust network architecture and configurations:
1.	Dilated Convolutions: These allow the receptive field to expand without reducing the spatial resolution of the feature maps. They are particularly useful in capturing larger contextual areas while maintaining fine details.
2.	Deeper Networks: Increasing the depth of the network naturally increases the receptive field. For lane detection, a deeper network can help capture both local details and larger scene context.
3.	Pooling Layers: Max or average pooling layers reduce spatial dimensions and hence expand the receptive field. However, pooling too early in the network may lose critical lane details.
4.	Encoder-Decoder Architectures: These are often used for semantic segmentation tasks like lane detection. The encoder gradually reduces the image size (increasing receptive field), while the decoder upsamples to the original size, preserving fine details for accurate lane boundary prediction.

## Methods


## Analysis and Results


# References

